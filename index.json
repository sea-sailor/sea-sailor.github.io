[{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/sail-sg/sailor2\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ca href=\"https://huggingface.co/collections/sail/sailor-65e19a749f978976f1959825\" class=\"btn external\" target=\"_blank\"\u003eHUGGING FACE\u003c/a\u003e\n\u003ca href=\"https://huggingface.co/spaces/sail/Sailor2-20B-Chat\" class=\"btn external\" target=\"_blank\"\u003eDEMO\u003c/a\u003e\n\u003ca href=\"https://huggingface.co/sailor2\" class=\"btn external\" target=\"_blank\"\u003eCOMMUNITY\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eIn this blog, we introduce \u003cstrong\u003eSailor2\u003c/strong\u003e, a community-driven initiative that brings cutting-edge multilingual language models to \u003cstrong\u003eSouth-East Asia (SEA)\u003c/strong\u003e. Our research highlights a strong demand for models in the \u003cstrong\u003e8B\u003c/strong\u003e and \u003cstrong\u003e20B\u003c/strong\u003e parameter range for production use, alongside a \u003cstrong\u003e1B\u003c/strong\u003e model for specialized applications, such as speculative decoding and research purposes. These models, released under the \u003cstrong\u003eApache 2.0 license\u003c/strong\u003e, provide enhanced accessibility to advanced language technologies across the region.\u003c/p\u003e","title":"Sailor2: Sailing in South-East Asia with Inclusive Multilingual LLMs"},{"summary":"\u003ca href=\"https://github.com/sail-sg/sailcraft\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eToday, we are thrilled to introduce the \u003cstrong\u003eSailCraft\u003c/strong\u003e data processing pipeline, a comprehensive open-source solution for large language model dataset curation. Built with meticulous attention to detail, Sailcraft represents a significant advancement in data preprocessing techniques for machine learning models.\u003c/p\u003e\n\u003cp\u003eThe pipeline encompasses a sophisticated four-stage data cleaning approach:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eInitial data cleaning\u003c/li\u003e\n\u003cli\u003eNear deduplication\u003c/li\u003e\n\u003cli\u003eExact deduplication\u003c/li\u003e\n\u003cli\u003eSecond-round data cleaning\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eWith a particular emphasis on linguistic diversity, Sailcraft provides specialized cleaning capabilities for a wide range of languages, including Arabic, Bengali, Catalan, Spanish, Basque, French, Hindi, Portuguese, Urdu, and optimized processing for English, Indonesian, Vietnamese, Chinese, Thai, Lao, and Malay.\u003c/p\u003e","title":"SailCraft: Data Toolkit for Sailor Language Models"},{"summary":"\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2404.03608\" class=\"btn external\" target=\"_blank\"\u003ePAPER\u003c/a\u003e\n\u003ca href=\"https://github.com/sail-sg/sailor-llm\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ca href=\"https://huggingface.co/collections/sail/sailor-65e19a749f978976f1959825\" class=\"btn external\" target=\"_blank\"\u003eHUGGING FACE\u003c/a\u003e\n\u003ca href=\"https://huggingface.co/spaces/sail/Sailor-14B-Chat\" class=\"btn external\" target=\"_blank\"\u003eDEMO\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eSailor is a suite of Open Language Models tailored for South-East Asia (SEA), focusing on languages such as ðŸ‡®ðŸ‡©Indonesian, ðŸ‡¹ðŸ‡­Thai, ðŸ‡»ðŸ‡³Vietnamese, ðŸ‡²ðŸ‡¾Malay, and ðŸ‡±ðŸ‡¦Lao. Developed with careful data curation, Sailor models are designed to understand and generate text across the diverse linguistic landscapes of the SEA region. Built from Qwen 1.5, Sailor encompasses models of varying sizes, spanning from 0.5B to 14B versions for different requirements.\u003c/p\u003e","title":"Sailor: Open Language Models for South-East Asia"}]