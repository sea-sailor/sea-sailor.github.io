<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Sailor: Open Language Models for South-East Asia | Sailor</title>
<meta name=keywords content><meta name=description content="PAPER
GITHUB
HUGGING FACE
DEMO
Introduction
Sailor is a suite of Open Language Models tailored for South-East Asia (SEA), focusing on languages such as ðŸ‡®ðŸ‡©Indonesian, ðŸ‡¹ðŸ‡­Thai, ðŸ‡»ðŸ‡³Vietnamese, ðŸ‡²ðŸ‡¾Malay, and ðŸ‡±ðŸ‡¦Lao. Developed with careful data curation, Sailor models are designed to understand and generate text across the diverse linguistic landscapes of the SEA region. Built from Qwen 1.5, Sailor encompasses models of varying sizes, spanning from 0.5B to 14B versions for different requirements."><meta name=author content="Sailor Team"><link rel=canonical href=http://sea-sailor.github.io/blog/sailor1/><link crossorigin=anonymous href=/assets/css/stylesheet.5535818ba8080a84fafce624766afd4112e9f8489b7a167457c88f8ea1398972.css integrity="sha256-VTWBi6gICoT6/OYkdmr9QRLp+EibehZ0V8iPjqE5iXI=" rel="preload stylesheet" as=style><link rel=icon href=http://sea-sailor.github.io/img/sailor_logo_trans.png><link rel=icon type=image/png sizes=16x16 href=http://sea-sailor.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://sea-sailor.github.io/favicon-32x32.png><link rel=apple-touch-icon href=http://sea-sailor.github.io/apple-touch-icon.png><link rel=mask-icon href=http://sea-sailor.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://sea-sailor.github.io/blog/sailor1/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-BP9G7L138H"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BP9G7L138H")}</script><meta property="og:title" content="Sailor: Open Language Models for South-East Asia"><meta property="og:description" content="PAPER
GITHUB
HUGGING FACE
DEMO
Introduction
Sailor is a suite of Open Language Models tailored for South-East Asia (SEA), focusing on languages such as ðŸ‡®ðŸ‡©Indonesian, ðŸ‡¹ðŸ‡­Thai, ðŸ‡»ðŸ‡³Vietnamese, ðŸ‡²ðŸ‡¾Malay, and ðŸ‡±ðŸ‡¦Lao. Developed with careful data curation, Sailor models are designed to understand and generate text across the diverse linguistic landscapes of the SEA region. Built from Qwen 1.5, Sailor encompasses models of varying sizes, spanning from 0.5B to 14B versions for different requirements."><meta property="og:type" content="article"><meta property="og:url" content="http://sea-sailor.github.io/blog/sailor1/"><meta property="og:image" content="http://sea-sailor.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-05-01T12:00:00+08:00"><meta property="article:modified_time" content="2024-05-01T12:00:00+08:00"><meta property="og:site_name" content="Sailor"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://sea-sailor.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Sailor: Open Language Models for South-East Asia"><meta name=twitter:description content="PAPER
GITHUB
HUGGING FACE
DEMO
Introduction
Sailor is a suite of Open Language Models tailored for South-East Asia (SEA), focusing on languages such as ðŸ‡®ðŸ‡©Indonesian, ðŸ‡¹ðŸ‡­Thai, ðŸ‡»ðŸ‡³Vietnamese, ðŸ‡²ðŸ‡¾Malay, and ðŸ‡±ðŸ‡¦Lao. Developed with careful data curation, Sailor models are designed to understand and generate text across the diverse linguistic landscapes of the SEA region. Built from Qwen 1.5, Sailor encompasses models of varying sizes, spanning from 0.5B to 14B versions for different requirements."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"http://sea-sailor.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Sailor: Open Language Models for South-East Asia","item":"http://sea-sailor.github.io/blog/sailor1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Sailor: Open Language Models for South-East Asia","name":"Sailor: Open Language Models for South-East Asia","description":"PAPER GITHUB HUGGING FACE DEMO\nIntroduction Sailor is a suite of Open Language Models tailored for South-East Asia (SEA), focusing on languages such as ðŸ‡®ðŸ‡©Indonesian, ðŸ‡¹ðŸ‡­Thai, ðŸ‡»ðŸ‡³Vietnamese, ðŸ‡²ðŸ‡¾Malay, and ðŸ‡±ðŸ‡¦Lao. Developed with careful data curation, Sailor models are designed to understand and generate text across the diverse linguistic landscapes of the SEA region. Built from Qwen 1.5, Sailor encompasses models of varying sizes, spanning from 0.5B to 14B versions for different requirements.\n","keywords":[],"articleBody":"PAPER GITHUB HUGGING FACE DEMO\nIntroduction Sailor is a suite of Open Language Models tailored for South-East Asia (SEA), focusing on languages such as ðŸ‡®ðŸ‡©Indonesian, ðŸ‡¹ðŸ‡­Thai, ðŸ‡»ðŸ‡³Vietnamese, ðŸ‡²ðŸ‡¾Malay, and ðŸ‡±ðŸ‡¦Lao. Developed with careful data curation, Sailor models are designed to understand and generate text across the diverse linguistic landscapes of the SEA region. Built from Qwen 1.5, Sailor encompasses models of varying sizes, spanning from 0.5B to 14B versions for different requirements.\nKey features of Sailor include:\nContinually pretrained on 200 Billion to 400 Billion tokens over 7 languages, including Indonesian, Thai, Vietnamese, Malay, Lao, English, and Chinese. Various model sizes (0.5B, 1.8B, 4B, 7B, 14B) to support different requirements. Strong performance on SEA benchmarks such as XQuAD, TydiQA, XCOPA, Belebele, and M3Exam. No restrictions on research and commercial use, but must comply with the Qwen 1.5 license. Built from Open-Source Community Sailor owes its existence to the open-source community. It is crafted by continually pre-training from language models like the remarkable Qwen 1.5 models, which already have great performance on SEA languages. The pre-training corpus heavily leverages the publicly available corpus, including SlimPajama, SkyPile, CC100, and MADLAD-400.\nBy employing aggressive data deduplication and careful data cleaning on the collected corpus, we have attained a high-quality dataset spanning various languages. Through systematic experiments to determine the weights of different languages, Sailor models undergo training from 200B to 400B tokens, tailored to different model sizes. The approach boosts their performance on SEA languages while maintaining proficiency in English and Chinese without significant compromise. Finally, we continually pre-train the Qwen1.5-0.5B model with 400 Billion tokens, and other models with 200 Billion tokens to obtain the Sailor models.\nFor most of the models, we use 200 billion tokens, with the effective tokens for each language as shown below. For models utilizing 400 billion tokens, they are doubled accordingly.\nLanguage Tokens (Billion) Indonesian (id) 51.56 Malay (ms) 7.91 Thai (th) 38.24 Vietnamese (vi) 41.50 Lao (lo) 0.34 English (en) 37.2 Chinese (zh) 22.64 Commitment to Open-Source Community The release of Sailor models marks the beginning of our commitment to open-source. In the coming weeks, we plan to release:\nTraining recipes Code for pre-training Pipeline for data cleaning and deduplication Pre-training corpus Benchmarking Performance Sailor models are evaluated across several high-quality benchmarks, encompassing four kinds of different tasks: question answering, commonsense reasoning, reading comprehension, and examination. We gratefully acknowledge the contributions of all dataset authors. For evaluation, following established protocols, we employed the awesome evaluation platform OpenCompass for comprehensive evaluation. The performance of all models is assessed based on the 3-shot Exact Match performance, with prompts provided in local languages (e.g., Indonesian task description for Indonesian tasks).\nWe acknowledge and respect the release of several SEA language models before, including SEA-LION, SeaLLMs, Typhoon, and VinaLLaMA. Here we mainly selected SeaLLMs-7B-Hybrid, its base model Llama-2-7B, SeaLLMs-7B-v2, and its base model Mistral-7B-v0.1 for performance comparison. Evaluation results for more models will be presented in our paper. Our reporting strictly adheres to the same evaluation methodology to ensure fair comparison, and we make much effort to closely match the reported results of the baseline.\nEvaluation Tasks Question Answering: XQuAD (Thai, Vietnamese) and TydiQA (Indonesian). Commonsense Reasoning: XCOPA (Indonesian, Thai, Vietnamese). Reading Comprehension: Belebele (Indonesian, Thai, Vietnamese). Examination: M3Exam (Javanese, Thai, Vietnamese). Question Answering All models are evaluated on the XQuAD and TydiQA benchmarks, with the 3-shot Exact Match (EM) and F1 score reported. Baselines which have better performance than Sailor models are highlighted in green. Sailor-14Bâ€™s XQuAD (th) result seem abnormal, with its predictions tending to be semantically equivalent but longer than the groundtruth, leading to lower EM and F1 scores compared to Qwen1.5.\n3-shot (EM / F1) XQuAD (th) TydiQA (id) XQuAD (vi) Qwen1.5-0.5B 14.19 / 23.35 20.71 / 32.64 19.85 / 35.38 Sailor-0.5B 15.84 / 27.58 30.44 / 54.74 21.13 / 40.57 Qwen1.5-1.8B 27.24 / 43.56 29.73 / 53.76 29.17 / 48.15 Sailor-1.8B 32.72 / 48.66 40.88 / 65.37 34.22 / 53.35 Qwen1.5-4B 34.03 / 53.40 48.32 / 72.68 43.71 / 63.86 Sailor-4B 46.82 / 63.34 53.98 / 73.48 47.65 / 67.09 Llama-2-7B 30.64 / 43.80 56.64 / 72.14 46.96 / 66.16 Mistral-7B-v0.1 48.48 / 63.27 63.54 / 78.73 53.72 / 72.75 SeaLLM-7B-Hybrid 49.70 / 67.62 50.62 / 75.21 49.62 / 70.74 SeaLLM-7B-v2 34.55 / 55.13 52.21 / 77.00 46.19 / 72.11 Qwen1.5-7B 53.79 / 69.30 57.17 / 77.28 56.63 / 76.99 Sailor-7B 57.88 / 71.06 60.53 / 75.42 53.81 / 74.62 Qwen1.5-14B 55.53 / 74.36 60.18 / 81.05 57.57 / 77.58 Sailor-14B 49.43* / 69.99* 58.94 / 77.85 57.83 / 77.37 Commonsense Reasoning All models are evaluated on the XCOPA benchmark, with the 3-shot accuracy reported.\n3-shot (EM) XCOPA (th) XCOPA (id) XCOPA (vi) Random Guess 50.00 50.00 50.00 Qwen1.5-0.5B 51.00 52.20 53.80 Sailor-0.5B 51.00 58.20 58.00 Qwen1.5-1.8B 52.60 51.60 53.40 Sailor-1.8B 53.80 64.20 63.20 Qwen1.5-4B 53.40 55.00 57.80 Sailor-4B 53.40 69.20 68.20 Llama-2-7B 52.80 64.00 62.00 Mistral-7B-v0.1 57.20 62.40 61.60 SeaLLM-7B-Hybrid 58.20 71.60 67.60 SeaLLM-7B-v2 56.80 64.00 64.60 Qwen1.5-7B 54.20 62.20 66.20 Sailor-7B 59.00 72.20 72.20 Qwen1.5-14B 60.00 72.20 74.00 Sailor-14B 64.40 79.60 80.40 Reading Comprehension All models are evaluated on the Belebele benchmark, with the 3-shot Exact Match (EM) reported. Baselines which have better performance than Sailor models are highlighted in green.\n3-shot (EM) Belebele (th) Belebele (id) Belebele (vi) Random Guess 25.00 25.00 25.00 Qwen1.5-0.5B 29.89 26.89 30.22 Sailor-0.5B 32.22 30.89 32.33 Qwen1.5-1.8B 30.11 32.00 31.33 Sailor-1.8B 34.22 34.89 35.33 Qwen1.5-4B 32.78 36.22 35.22 Sailor-4B 36.11 41.33 38.89 Llama-2-7B 31.78 39.78 38.00 Mistral-7B-v0.1 34.33 41.33 41.33 SeaLLM-7B-Hybrid 37.78 43.11 43.00 SeaLLM-7B-v2 36.33 43.11 47.00 Qwen1.5-7B 38.33 42.00 42.89 Sailor-7B 41.56 44.33 45.33 Qwen1.5-14B 41.44 46.22 40.33 Sailor-14B 42.11 47.56 45.89 Examination All models are evaluated on the M3Exam benchmark, with the 3-shot Exact Match (EM) reported. The code jv is short for Javanese, which is a language spoken in Indonesia.\n3-shot (EM) M3Exam (th) M3Exam (jv) M3Exam (vi) Qwen1.5-0.5B 22.38 22.10 29.12 Sailor-0.5B 21.87 28.84 23.53 Qwen1.5-1.8B 23.81 26.15 36.39 Sailor-1.8B 23.90 29.65 27.67 Qwen1.5-4B 26.26 30.19 40.02 Sailor-4B 27.23 29.11 31.58 Llama-2-7B 21.13 23.99 34.14 Mistral-7B-v0.1 29.59 31.00 43.54 Sea-Lion-7B 23.90 21.56 26.89 SeaLLM-7B-Hybrid 25.98 24.53 38.79 SeaLLM-7B-v2 35.60 29.92 50.36 Qwen1.5-7B 35.88 33.15 51.09 Sailor-7B 38.33 35.85 51.98 Qwen1.5-14B 43.18 35.04 58.47 Sailor-14B 48.22 39.89 60.54 Contributors Longxu Dou, Sea AI Lab Qian Liu, Sea AI Lab Guangtao Zeng, SUTD Jia Guo, NUS Jiahui Zhou, Sea AI Lab Ziqi Jin, SUTD Xin Mao, NTU Wei Lu, SUTD Min Lin, Sea AI Lab Contact Us Sailor models are free for research and commercial use, but you should also obey the Qwen 1.5 license. We encourage you to use Sailor models in your research and applications.\nFor questions or collaboration, please:\nRaise an issue in our GitHub repository Contact us at: doulx@sea.com liuqian.sea@gmail.com Citation @article{dou2024sailor, title={Sailor: Open Language Models for South-East Asia}, author={Dou, Longxu and Liu, Qian and Zeng, Guangtao and Guo, Jia and Zhou, Jiahui and Lu, Wei and Lin, Min}, journal={arXiv preprint arXiv:2404.03608}, year={2024} } ","wordCount":"1155","inLanguage":"en","datePublished":"2024-05-01T12:00:00+08:00","dateModified":"2024-05-01T12:00:00+08:00","author":{"@type":"Person","name":"Sailor Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://sea-sailor.github.io/blog/sailor1/"},"publisher":{"@type":"Organization","name":"Sailor","logo":{"@type":"ImageObject","url":"http://sea-sailor.github.io/img/sailor_logo_trans.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Sailor (Alt + H)"></a><div class=logo-switches></div></div><ul id=menu><li><a href=/ title=Home><span>Home</span></a></li><li><a href=/resources title=Resources><span>Resources</span></a></li><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Sailor: Open Language Models for South-East Asia</h1><div class=post-meta><span title='2024-05-01 12:00:00 +0800 +0800'>May 1, 2024</span>&nbsp;Â·&nbsp;6 min&nbsp;Â·&nbsp;1155 words&nbsp;Â·&nbsp;Sailor Team</div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://arxiv.org/abs/2404.03608 class="btn external" target=_blank>PAPER</a>
<a href=https://github.com/sail-sg/sailor-llm class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/collections/sail/sailor-65e19a749f978976f1959825 class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://huggingface.co/spaces/sail/Sailor-14B-Chat class="btn external" target=_blank>DEMO</a></p><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>Sailor is a suite of Open Language Models tailored for South-East Asia (SEA), focusing on languages such as ðŸ‡®ðŸ‡©Indonesian, ðŸ‡¹ðŸ‡­Thai, ðŸ‡»ðŸ‡³Vietnamese, ðŸ‡²ðŸ‡¾Malay, and ðŸ‡±ðŸ‡¦Lao. Developed with careful data curation, Sailor models are designed to understand and generate text across the diverse linguistic landscapes of the SEA region. Built from Qwen 1.5, Sailor encompasses models of varying sizes, spanning from 0.5B to 14B versions for different requirements.</p><p>Key features of Sailor include:</p><ul><li>Continually pretrained on <strong>200 Billion to 400 Billion</strong> tokens over 7 languages, including Indonesian, Thai, Vietnamese, Malay, Lao, English, and Chinese.</li><li>Various model sizes (<strong>0.5B</strong>, <strong>1.8B</strong>, <strong>4B</strong>, <strong>7B</strong>, <strong>14B</strong>) to support different requirements.</li><li>Strong performance on SEA benchmarks such as XQuAD, TydiQA, XCOPA, Belebele, and M3Exam.</li><li>No restrictions on research and commercial use, but must comply with the Qwen 1.5 license.</li></ul><h2 id=built-from-open-source-community>Built from Open-Source Community<a hidden class=anchor aria-hidden=true href=#built-from-open-source-community>#</a></h2><p>Sailor owes its existence to the open-source community. It is crafted by continually pre-training from language models like the remarkable <a href=https://qwenlm.github.io/blog/qwen1.5/>Qwen 1.5</a> models, which already have great performance on SEA languages. The pre-training corpus heavily leverages the publicly available corpus, including <a href=https://huggingface.co/datasets/cerebras/SlimPajama-627B>SlimPajama</a>, <a href=https://huggingface.co/datasets/Skywork/SkyPile-150B>SkyPile</a>, <a href=https://huggingface.co/datasets/cc100>CC100</a>, and <a href=https://huggingface.co/datasets/allenai/MADLAD-400>MADLAD-400</a>.</p><p>By employing aggressive data deduplication and careful data cleaning on the collected corpus, we have attained a high-quality dataset spanning various languages. Through systematic experiments to determine the weights of different languages, Sailor models undergo training from 200B to 400B tokens, tailored to different model sizes. The approach boosts their performance on SEA languages while maintaining proficiency in English and Chinese without significant compromise. Finally, we continually pre-train the Qwen1.5-0.5B model with 400 Billion tokens, and other models with 200 Billion tokens to obtain the Sailor models.</p><p>For most of the models, we use 200 billion tokens, with the effective tokens for each language as shown below. For models utilizing 400 billion tokens, they are doubled accordingly.</p><table><thead><tr><th><strong>Language</strong></th><th><strong>Tokens (Billion)</strong></th></tr></thead><tbody><tr><td>Indonesian (id)</td><td>51.56</td></tr><tr><td>Malay (ms)</td><td>7.91</td></tr><tr><td>Thai (th)</td><td>38.24</td></tr><tr><td>Vietnamese (vi)</td><td>41.50</td></tr><tr><td>Lao (lo)</td><td>0.34</td></tr><tr><td>English (en)</td><td>37.2</td></tr><tr><td>Chinese (zh)</td><td>22.64</td></tr></tbody></table><h2 id=commitment-to-open-source-community>Commitment to Open-Source Community<a hidden class=anchor aria-hidden=true href=#commitment-to-open-source-community>#</a></h2><p>The release of Sailor models marks the beginning of our commitment to open-source. In the coming weeks, we plan to release:</p><ul><li>Training recipes</li><li>Code for pre-training</li><li>Pipeline for data cleaning and deduplication</li><li>Pre-training corpus</li></ul><h2 id=benchmarking-performance>Benchmarking Performance<a hidden class=anchor aria-hidden=true href=#benchmarking-performance>#</a></h2><p>Sailor models are evaluated across several high-quality benchmarks, encompassing four kinds of different tasks: question answering, commonsense reasoning, reading comprehension, and examination. We gratefully acknowledge the contributions of all dataset authors. For evaluation, following established protocols, we employed the awesome evaluation platform <a href=https://github.com/open-compass/opencompass>OpenCompass</a> for comprehensive evaluation. The performance of all models is assessed based on the 3-shot Exact Match performance, with prompts provided in local languages (e.g., Indonesian task description for Indonesian tasks).</p><p>We acknowledge and respect the release of several SEA language models before, including <a href=https://aisingapore.org/aiproducts/sea-lion/>SEA-LION</a>, <a href=https://arxiv.org/abs/2312.00738>SeaLLMs</a>, <a href=https://arxiv.org/abs/2312.13951>Typhoon</a>, and <a href=https://arxiv.org/abs/2312.11011>VinaLLaMA</a>. Here we mainly selected <a href=https://huggingface.co/SeaLLMs/SeaLLM-7B-Hybrid>SeaLLMs-7B-Hybrid</a>, its base model <a href=https://huggingface.co/meta-llama/Llama-2-7B>Llama-2-7B</a>, <a href=https://huggingface.co/SeaLLMs/SeaLLM-7B-v2>SeaLLMs-7B-v2</a>, and its base model <a href=https://huggingface.co/mistralai/Mistral-7B-v0.1>Mistral-7B-v0.1</a> for performance comparison. Evaluation results for more models will be presented in our paper. Our reporting strictly adheres to the same evaluation methodology to ensure fair comparison, and we make much effort to closely match the reported results of the baseline.</p><h3 id=evaluation-tasks>Evaluation Tasks<a hidden class=anchor aria-hidden=true href=#evaluation-tasks>#</a></h3><ul><li><strong>Question Answering</strong>: <a href=https://arxiv.org/abs/1910.11856>XQuAD</a> (Thai, Vietnamese) and <a href=https://arxiv.org/abs/2003.05002>TydiQA</a> (Indonesian).</li><li><strong>Commonsense Reasoning</strong>: <a href=https://aclanthology.org/2020.emnlp-main.185/>XCOPA</a> (Indonesian, Thai, Vietnamese).</li><li><strong>Reading Comprehension</strong>: <a href=https://arxiv.org/abs/2308.16884>Belebele</a> (Indonesian, Thai, Vietnamese).</li><li><strong>Examination</strong>: <a href=https://arxiv.org/abs/2306.05179>M3Exam</a> (Javanese, Thai, Vietnamese).</li></ul><h3 id=question-answering>Question Answering<a hidden class=anchor aria-hidden=true href=#question-answering>#</a></h3><p>All models are evaluated on the XQuAD and TydiQA benchmarks, with the 3-shot Exact Match (EM) and F1 score reported. Baselines which have better performance than Sailor models are highlighted in green. Sailor-14B&rsquo;s XQuAD (th) result seem abnormal, with its predictions tending to be semantically equivalent but longer than the groundtruth, leading to lower EM and F1 scores compared to Qwen1.5.</p><table><thead><tr><th>3-shot (EM / F1)</th><th>XQuAD (th)</th><th>TydiQA (id)</th><th>XQuAD (vi)</th></tr></thead><tbody><tr><td>Qwen1.5-0.5B</td><td>14.19 / 23.35</td><td>20.71 / 32.64</td><td>19.85 / 35.38</td></tr><tr><td><strong>Sailor-0.5B</strong></td><td>15.84 / 27.58</td><td>30.44 / 54.74</td><td>21.13 / 40.57</td></tr><tr><td>Qwen1.5-1.8B</td><td>27.24 / 43.56</td><td>29.73 / 53.76</td><td>29.17 / 48.15</td></tr><tr><td><strong>Sailor-1.8B</strong></td><td>32.72 / 48.66</td><td>40.88 / 65.37</td><td>34.22 / 53.35</td></tr><tr><td>Qwen1.5-4B</td><td>34.03 / 53.40</td><td>48.32 / 72.68</td><td>43.71 / 63.86</td></tr><tr><td><strong>Sailor-4B</strong></td><td>46.82 / 63.34</td><td>53.98 / 73.48</td><td>47.65 / 67.09</td></tr><tr><td>Llama-2-7B</td><td>30.64 / 43.80</td><td>56.64 / 72.14</td><td>46.96 / 66.16</td></tr><tr><td>Mistral-7B-v0.1</td><td>48.48 / 63.27</td><td>63.54 / 78.73</td><td>53.72 / 72.75</td></tr><tr><td>SeaLLM-7B-Hybrid</td><td>49.70 / 67.62</td><td>50.62 / 75.21</td><td>49.62 / 70.74</td></tr><tr><td>SeaLLM-7B-v2</td><td>34.55 / 55.13</td><td>52.21 / 77.00</td><td>46.19 / 72.11</td></tr><tr><td>Qwen1.5-7B</td><td>53.79 / 69.30</td><td>57.17 / 77.28</td><td>56.63 / 76.99</td></tr><tr><td><strong>Sailor-7B</strong></td><td>57.88 / 71.06</td><td>60.53 / 75.42</td><td>53.81 / 74.62</td></tr><tr><td>Qwen1.5-14B</td><td>55.53 / 74.36</td><td>60.18 / 81.05</td><td>57.57 / 77.58</td></tr><tr><td><strong>Sailor-14B</strong></td><td>49.43* / 69.99*</td><td>58.94 / 77.85</td><td>57.83 / 77.37</td></tr></tbody></table><h3 id=commonsense-reasoning>Commonsense Reasoning<a hidden class=anchor aria-hidden=true href=#commonsense-reasoning>#</a></h3><p>All models are evaluated on the XCOPA benchmark, with the 3-shot accuracy reported.</p><table><thead><tr><th>3-shot (EM)</th><th>XCOPA (th)</th><th>XCOPA (id)</th><th>XCOPA (vi)</th></tr></thead><tbody><tr><td>Random Guess</td><td>50.00</td><td>50.00</td><td>50.00</td></tr><tr><td>Qwen1.5-0.5B</td><td>51.00</td><td>52.20</td><td>53.80</td></tr><tr><td><strong>Sailor-0.5B</strong></td><td>51.00</td><td>58.20</td><td>58.00</td></tr><tr><td>Qwen1.5-1.8B</td><td>52.60</td><td>51.60</td><td>53.40</td></tr><tr><td><strong>Sailor-1.8B</strong></td><td>53.80</td><td>64.20</td><td>63.20</td></tr><tr><td>Qwen1.5-4B</td><td>53.40</td><td>55.00</td><td>57.80</td></tr><tr><td><strong>Sailor-4B</strong></td><td>53.40</td><td>69.20</td><td>68.20</td></tr><tr><td>Llama-2-7B</td><td>52.80</td><td>64.00</td><td>62.00</td></tr><tr><td>Mistral-7B-v0.1</td><td>57.20</td><td>62.40</td><td>61.60</td></tr><tr><td>SeaLLM-7B-Hybrid</td><td>58.20</td><td>71.60</td><td>67.60</td></tr><tr><td>SeaLLM-7B-v2</td><td>56.80</td><td>64.00</td><td>64.60</td></tr><tr><td>Qwen1.5-7B</td><td>54.20</td><td>62.20</td><td>66.20</td></tr><tr><td><strong>Sailor-7B</strong></td><td>59.00</td><td>72.20</td><td>72.20</td></tr><tr><td>Qwen1.5-14B</td><td>60.00</td><td>72.20</td><td>74.00</td></tr><tr><td><strong>Sailor-14B</strong></td><td>64.40</td><td>79.60</td><td>80.40</td></tr></tbody></table><h3 id=reading-comprehension>Reading Comprehension<a hidden class=anchor aria-hidden=true href=#reading-comprehension>#</a></h3><p>All models are evaluated on the Belebele benchmark, with the 3-shot Exact Match (EM) reported. Baselines which have better performance than Sailor models are highlighted in green.</p><table><thead><tr><th>3-shot (EM)</th><th>Belebele (th)</th><th>Belebele (id)</th><th>Belebele (vi)</th></tr></thead><tbody><tr><td>Random Guess</td><td>25.00</td><td>25.00</td><td>25.00</td></tr><tr><td>Qwen1.5-0.5B</td><td>29.89</td><td>26.89</td><td>30.22</td></tr><tr><td><strong>Sailor-0.5B</strong></td><td>32.22</td><td>30.89</td><td>32.33</td></tr><tr><td>Qwen1.5-1.8B</td><td>30.11</td><td>32.00</td><td>31.33</td></tr><tr><td><strong>Sailor-1.8B</strong></td><td>34.22</td><td>34.89</td><td>35.33</td></tr><tr><td>Qwen1.5-4B</td><td>32.78</td><td>36.22</td><td>35.22</td></tr><tr><td><strong>Sailor-4B</strong></td><td>36.11</td><td>41.33</td><td>38.89</td></tr><tr><td>Llama-2-7B</td><td>31.78</td><td>39.78</td><td>38.00</td></tr><tr><td>Mistral-7B-v0.1</td><td>34.33</td><td>41.33</td><td>41.33</td></tr><tr><td>SeaLLM-7B-Hybrid</td><td>37.78</td><td>43.11</td><td>43.00</td></tr><tr><td>SeaLLM-7B-v2</td><td>36.33</td><td>43.11</td><td>47.00</td></tr><tr><td>Qwen1.5-7B</td><td>38.33</td><td>42.00</td><td>42.89</td></tr><tr><td><strong>Sailor-7B</strong></td><td>41.56</td><td>44.33</td><td>45.33</td></tr><tr><td>Qwen1.5-14B</td><td>41.44</td><td>46.22</td><td>40.33</td></tr><tr><td><strong>Sailor-14B</strong></td><td>42.11</td><td>47.56</td><td>45.89</td></tr></tbody></table><h3 id=examination>Examination<a hidden class=anchor aria-hidden=true href=#examination>#</a></h3><p>All models are evaluated on the M3Exam benchmark, with the 3-shot Exact Match (EM) reported. The code jv is short for Javanese, which is a language spoken in Indonesia.</p><table><thead><tr><th>3-shot (EM)</th><th>M3Exam (th)</th><th>M3Exam (jv)</th><th>M3Exam (vi)</th></tr></thead><tbody><tr><td>Qwen1.5-0.5B</td><td>22.38</td><td>22.10</td><td>29.12</td></tr><tr><td><strong>Sailor-0.5B</strong></td><td>21.87</td><td>28.84</td><td>23.53</td></tr><tr><td>Qwen1.5-1.8B</td><td>23.81</td><td>26.15</td><td>36.39</td></tr><tr><td><strong>Sailor-1.8B</strong></td><td>23.90</td><td>29.65</td><td>27.67</td></tr><tr><td>Qwen1.5-4B</td><td>26.26</td><td>30.19</td><td>40.02</td></tr><tr><td><strong>Sailor-4B</strong></td><td>27.23</td><td>29.11</td><td>31.58</td></tr><tr><td>Llama-2-7B</td><td>21.13</td><td>23.99</td><td>34.14</td></tr><tr><td>Mistral-7B-v0.1</td><td>29.59</td><td>31.00</td><td>43.54</td></tr><tr><td>Sea-Lion-7B</td><td>23.90</td><td>21.56</td><td>26.89</td></tr><tr><td>SeaLLM-7B-Hybrid</td><td>25.98</td><td>24.53</td><td>38.79</td></tr><tr><td>SeaLLM-7B-v2</td><td>35.60</td><td>29.92</td><td>50.36</td></tr><tr><td>Qwen1.5-7B</td><td>35.88</td><td>33.15</td><td>51.09</td></tr><tr><td><strong>Sailor-7B</strong></td><td>38.33</td><td>35.85</td><td>51.98</td></tr><tr><td>Qwen1.5-14B</td><td>43.18</td><td>35.04</td><td>58.47</td></tr><tr><td><strong>Sailor-14B</strong></td><td>48.22</td><td>39.89</td><td>60.54</td></tr></tbody></table><h2 id=contributors>Contributors<a hidden class=anchor aria-hidden=true href=#contributors>#</a></h2><ul><li>Longxu Dou, Sea AI Lab</li><li>Qian Liu, Sea AI Lab</li><li>Guangtao Zeng, SUTD</li><li>Jia Guo, NUS</li><li>Jiahui Zhou, Sea AI Lab</li><li>Ziqi Jin, SUTD</li><li>Xin Mao, NTU</li><li>Wei Lu, SUTD</li><li>Min Lin, Sea AI Lab</li></ul><h2 id=contact-us>Contact Us<a hidden class=anchor aria-hidden=true href=#contact-us>#</a></h2><p>Sailor models are free for research and commercial use, but you should also obey the <a href=https://huggingface.co/Qwen/Qwen1.5-0.5B/blob/main/LICENSE>Qwen 1.5 license</a>. We encourage you to use Sailor models in your research and applications.</p><p>For questions or collaboration, please:</p><ul><li>Raise an issue in our GitHub repository</li><li>Contact us at:<ul><li><a href=mailto:doulx@sea.com>doulx@sea.com</a></li><li><a href=mailto:liuqian.sea@gmail.com>liuqian.sea@gmail.com</a></li></ul></li></ul><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><pre tabindex=0><code>@article{dou2024sailor,
  title={Sailor: Open Language Models for South-East Asia},
  author={Dou, Longxu and Liu, Qian and Zeng, Guangtao and Guo, Jia and Zhou, Jiahui and Lu, Wei and Lin, Min},
  journal={arXiv preprint arXiv:2404.03608},
  year={2024}
}
</code></pre></div></article></main><footer class=footer><span>&copy; 2025 <a href=http://sea-sailor.github.io/>Sailor</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a>
</span><span>Acknowledgment to
<a href=https://qwenlm.github.io/ rel="noopener noreferrer" target=_blank>Qwen</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>